{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7af9e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad12c6f",
   "metadata": {},
   "source": [
    "expected data:\n",
    "- job url\n",
    "- job title\n",
    "- location\n",
    "- salary\n",
    "- experience\n",
    "- tags\n",
    "- jd\n",
    "- company info (scale, field, company name, ...)\n",
    "- categories (related jobs, skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8e996f",
   "metadata": {},
   "source": [
    "### utils ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_urls(max_page):\n",
    "    job_detail_urls = []\n",
    "\n",
    "    for page in range(1, max_page+1):\n",
    "        url = f\"https://www.topcv.vn/tim-viec-lam-cong-nghe-thong-tin-cr257?sort=new&type_keyword=1&page={page}&category_family=r257\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        jobs = soup.find_all('div', attrs={\"data-box\":\"BoxSearchResult\"}) # len(jobs)=50, the maximum number of jobs in one single page\n",
    "        \n",
    "        for job in jobs:\n",
    "            job_detail_urls.append(job.find('h3', class_='title').find('a')['href'])\n",
    "\n",
    "    return job_detail_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81285ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_content(url):\n",
    "    headers = {\n",
    "        'User-Agent': ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "                       'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:54.0) Gecko/20100101 Firefox/54.0',\n",
    "                       'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/11.1 Safari/605.1.15',\n",
    "                       'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36']\n",
    "        }\n",
    "    response = requests.get(url, headers={'User-Agent': random.choice(headers['User-Agent'])})\n",
    "\n",
    "    # handle request failure\n",
    "    if response.status_code != 200:\n",
    "        for i in range(5):\n",
    "            print('failed to retrieve: ' + url)\n",
    "            print('will retry after 60s...')\n",
    "            time.sleep(60)\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                break\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print('failed to retrieve after 5 retries: ' + url)\n",
    "            return None\n",
    "        \n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4777e4fc",
   "metadata": {},
   "source": [
    "From my exploration, IT jobs on topcv.vn can now be categorized into 3 types based on the contract between topcv and the company posting the jobs:\n",
    "1. Normal jobs (https://www.topcv.vn/viec-lam/...)\n",
    "2. Brand: (https://www.topcv.vn/brand/...)\n",
    "    - Premium Brand\n",
    "    - Brand\n",
    "\n",
    "Each type has a different HTML structure, which requires separate handling efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f8ff01",
   "metadata": {},
   "source": [
    "### 1. Normal jobs ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c886b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_jd_normal_job(job):\n",
    "    jd = {}\n",
    "    all_sections = job.find('div', class_='job-description').find_all('div', class_='job-description__item') # sections in jd part of html\n",
    "    for section in all_sections:\n",
    "        title = section.find('h3').get_text(strip=True)\n",
    "        if section.find_all('li'):\n",
    "            content = \"\\n\".join([c.get_text(strip=True) for c in section.find_all('li')])\n",
    "        else:\n",
    "            content = section.find('div').get_text(strip=True, separator='\\n')\n",
    "            \n",
    "        jd[title] = content\n",
    "        \n",
    "    # custom form job (job co job khong)\n",
    "    cfj = job.find_all('div', class_='custom-form-job__item')\n",
    "    if len(cfj) > 0:    \n",
    "        for form in cfj:\n",
    "            title = form.find('h3').get_text(strip=True)\n",
    "            content = form.find('div', class_='custom-form-job__item--content').get_text(strip=True)\n",
    "\n",
    "            jd[title] = content\n",
    "        \n",
    "    return jd\n",
    "\n",
    "\n",
    "def extract_general_info_normal_job(job):\n",
    "    # thong tin chung\n",
    "    general_inf = {}\n",
    "    all_general_inf = job.find('div', class_='job-detail__box--right job-detail__body-right--item job-detail__body-right--box-general').find_all('div', class_='box-general-group-info')\n",
    "    \n",
    "    for inf in all_general_inf:\n",
    "        title = inf.find('div', class_='box-general-group-info-title').get_text(strip=True)\n",
    "        value = inf.find('div', class_='box-general-group-info-value').get_text(strip=True)\n",
    "        general_inf[title] = value\n",
    "        \n",
    "    return general_inf\n",
    "\n",
    "\n",
    "def extract_categories_box_normal_job(job):\n",
    "    categories = {}\n",
    "    \n",
    "    categories_box = job.find('div', class_=\"job-detail__box--right job-detail__body-right--item job-detail__body-right--box-category\")\\\n",
    "                        .find_all('div', class_=['box-category', 'box-category-collapsed'])\n",
    "    \n",
    "    for category in categories_box:\n",
    "        title = category.find('div', class_='box-title').get_text(strip=True)\n",
    "        a = category.find('div', class_='box-category-tags').find_all('a')\n",
    "        if a:\n",
    "            tags = [tag.get_text(strip=True) for tag in category.find('div', class_='box-category-tags').find_all('a')]\n",
    "        else:\n",
    "            tags = [tag.get_text(strip=True) for tag in category.find('div', class_='box-category-tags').find_all('span')]\n",
    "        categories[title] = tags\n",
    "\n",
    "    return categories\n",
    "\n",
    "\n",
    "def scrape_normal_job(url):\n",
    "    response_content = get_page_content(url)\n",
    "    if response_content is None:\n",
    "        print('failed to get page content: ' + url)\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response_content, \"html.parser\")\n",
    "\n",
    "    # parse html\n",
    "    job = soup.find('div', class_='job-detail__body')\n",
    "    \n",
    "    if job is None:\n",
    "        print('failed to parse: ' + url)\n",
    "        return None\n",
    "    \n",
    "    # extract data\n",
    "    job_title = job.find('h1', class_='job-detail__info--title').get_text(strip=True, separator=' ')\n",
    "    \n",
    "    infs = job.find_all('div', class_='job-detail__info--section-content-value')\n",
    "    salary = infs[0].get_text(strip=True)\n",
    "    location = infs[1].get_text(strip=True)\n",
    "    exp = infs[2].get_text(strip=True)\n",
    "    \n",
    "    # deadline = datetime.strptime(job.find('div', class_='job-detail__info--deadline').get_text(strip=True)[15:], \"%d/%m/%Y\")\n",
    "    deadline = job.find('div', class_='job-detail__info--deadline').get_text(strip=True)[15:]\n",
    "    \n",
    "    jd_tags = [a.get_text(strip=True) for a in job.find_all('a', class_='item search-from-tag link')]\n",
    "    \n",
    "    jd = extract_jd_normal_job(job)\n",
    "    \n",
    "    # company info\n",
    "    company_name = job.find('div', class_='company-name-label').find('a', class_='name').get_text(strip=True)\n",
    "    company_scale = job.find('div', class_='job-detail__company--information-item company-scale').find('div', class_='company-value').get_text(strip=True)\n",
    "    company_address = job.find('div', class_='job-detail__company--information-item company-address').find('div', class_='company-value').get_text(strip=True)\n",
    "    company_field = job.find('div', class_='job-detail__company--information-item company-field').find('div', class_='company-value').get_text(strip=True)\n",
    "\n",
    "    general_inf = extract_general_info_normal_job(job)\n",
    "    \n",
    "    categories = extract_categories_box_normal_job(job)\n",
    "\n",
    "    job.clear()\n",
    "    \n",
    "    return {\n",
    "        'url': url, \n",
    "        'title': job_title, \n",
    "        'location': location, \n",
    "        'salary': salary, \n",
    "        'exp': exp, \n",
    "        'deadline': deadline, \n",
    "        'jd_tags': jd_tags, \n",
    "        'jd': jd, \n",
    "        'company_info': {\n",
    "            'company_name': company_name, \n",
    "            'company_scale': company_scale, \n",
    "            'company_address': company_address, \n",
    "            'company_field': company_field\n",
    "        }, \n",
    "        'general_inf': general_inf, \n",
    "        'categories': categories\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85117dbd",
   "metadata": {},
   "source": [
    "### 2. Brand ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab624348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_brand_job(url):\n",
    "\n",
    "    response_content = get_page_content(url)\n",
    "    if response_content is None:\n",
    "        print('failed to get page content: ' + url)\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response_content, \"html.parser\")\n",
    "\n",
    "    job = soup.find('div', class_='block-left')\n",
    "\n",
    "    job_title = job.find('h2', class_='title').get_text(strip=True)\n",
    "\n",
    "    details = job.find('div', class_='box-job-info').find_all('div', class_='box-info')\n",
    "\n",
    "    # theo nhu exploration thi cac class 'box-info' trong phan job details gom: general info, job tags va job description\n",
    "\n",
    "    jd = {}\n",
    "    general_info = {}\n",
    "    job_tags = []\n",
    "\n",
    "    for section in details:\n",
    "        # general info\n",
    "        if section.find('div', class_='box-main'):\n",
    "            items = section.find('div', class_='box-main').find_all('div', class_='box-item')\n",
    "            for item in items:\n",
    "                label = item.find('strong').get_text(strip=True)\n",
    "                value = item.find('span').get_text(strip=True)\n",
    "                # print(f\"{label}: {value}\")\n",
    "                general_info[label] = value\n",
    "\n",
    "        # jd    \n",
    "        else:\n",
    "            title = section.find('h2').get_text(strip=True)\n",
    "            content_div = section.find('div', class_='content-tab').find_all()\n",
    "            content = \"\"\n",
    "            for part in content_div:\n",
    "                if part.name == 'ul':\n",
    "                    lis = part.find_all('li')\n",
    "                    for li in lis:\n",
    "                        content += \"- \" + li.get_text(strip=True) + \"\\n\"\n",
    "                elif part.name == 'div' or part.name == 'p':\n",
    "                    content += part.get_text(strip=True) + \"\\n\"\n",
    "            jd[title] = content\n",
    "\n",
    "            # custom form job (job co job khong)\n",
    "            cfj = section.find_all('div', class_='custom-form-job__item')\n",
    "            if len(cfj) > 0:    \n",
    "                for div in cfj:\n",
    "                    title = div.find('h3').get_text(strip=True) \n",
    "                    content = div.find('div', class_='custom-form-job__item--content').get_text(strip=True)\n",
    "                    # print(f\"{title}: {content}\")\n",
    "                    jd[title] = content\n",
    "\n",
    "            # job tags (phan nay co trong \"mo ta cong viec\")\n",
    "            if section.find('div', class_='job-tags'):\n",
    "                tags = section.find('div', class_='job-tags').find_all('a')\n",
    "                for tag in tags:\n",
    "                    # print(tag.get_text(strip=True))\n",
    "                    job_tags.append(tag.get_text(strip=True))\n",
    "\n",
    "\n",
    "    # address \n",
    "    address_div = job.find('div', class_='box-job-info').find('div', class_='box-address')\n",
    "    address = \"\\n\".join([a.get_text(strip=True) for a in address_div.find_all()])\n",
    "\n",
    "    # company (phan nay trong footer)\n",
    "    company = {}\n",
    "    footer = soup.find('div', class_='footer-info')\n",
    "    company['name'] = footer.find('div', class_='footer-info-content footer-info-company-name').get_text(strip=True)\n",
    "    title_divs = footer.find_all('div', class_='footer-info-title')\n",
    "\n",
    "    for title in title_divs:\n",
    "        if title.find_next('div').get('class')[0] == 'footer-info-content':\n",
    "            company[title.get_text(strip=True)] = title.find_next('div').get_text(strip=True)\n",
    "\n",
    "\n",
    "    return {\n",
    "        'url': url, \n",
    "        'title': job_title, \n",
    "        'address': address, \n",
    "        'general_info': general_info, \n",
    "        'job_tags': job_tags, \n",
    "        'jd': jd, \n",
    "        'company': company\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55ff22a",
   "metadata": {},
   "source": [
    "### 3. Premium ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fec9d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jd\n",
    "def extract_jd_premium(job):\n",
    "    jd = {}\n",
    "    boxes = job.find_all('div', class_='premium-job-description__box')\n",
    "    for box in boxes:\n",
    "        label = box.find('h2').get_text(strip=True)\n",
    "    #     print(lable)\n",
    "        if box.find_all('li'):\n",
    "            content = \"\\n\".join([c.get_text(strip=True) for c in box.find_all('li')])\n",
    "        else:\n",
    "            content = box.find('div').get_text(strip=True, separator='\\n')\n",
    "    #     print(content)\n",
    "    #     print('-----')\n",
    "\n",
    "        jd[label] = content\n",
    "    return jd\n",
    "\n",
    "\n",
    "def extract_general_info_premium(job):\n",
    "    general_info = {}\n",
    "    general_info_data = job.find_all('div', class_='general-information-data')\n",
    "    for data in general_info_data:\n",
    "        label = data.find('div', class_='general-information-data__label').get_text(strip=True)\n",
    "        value = data.find('div', class_='general-information-data__value').get_text(strip=True)\n",
    "    #     print(label + ': ' + value)\n",
    "        general_info[label] = value\n",
    "    return general_info\n",
    "\n",
    "\n",
    "def extract_related_tags_premium(job):\n",
    "    related_tags = {}\n",
    "\n",
    "    job_related_tags = job.find_all('div', class_=[\"premium-job-related-tags__section\", \"premium-job-related-tags__section box-category collapsed\"])\n",
    "\n",
    "    for section in job_related_tags:\n",
    "        title = section.find('h2', class_='premium-job-box__title').get_text(strip=True)\n",
    "        tags = [tag.get_text(strip=True) for tag in section.find_all(class_='tag-item')]\n",
    "    #     print(title)\n",
    "    #     print(tags)\n",
    "        related_tags[title] = tags\n",
    "    return related_tags\n",
    "\n",
    "\n",
    "def scrape_premium_brand_job(url):\n",
    "    response_content = get_page_content(url)\n",
    "    if response_content is None:\n",
    "        print('failed to get page content: ' + url)\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response_content, \"html.parser\")\n",
    "\n",
    "    job = soup.find('div', class_='premium-job')\n",
    "    \n",
    "    job_title = job.find('h2', class_='premium-job-basic-information__content--title').get_text(strip=True)\n",
    "    \n",
    "    info_sections = job.find('div', class_='premium-job-basic-information__content--sections').find_all('div', class_=\"basic-information-item\")\n",
    "    salary = info_sections[0].find('div', class_='basic-information-item__data--value').get_text(strip=True)\n",
    "    location = info_sections[1].find('div', class_='basic-information-item__data--value').get_text(strip=True)\n",
    "    exp = info_sections[2].find('div', class_='basic-information-item__data--value').get_text(strip=True)\n",
    "    \n",
    "    job_tags = [tag.get_text(strip=True) for tag in job.find('div', class_='job-tags').find_all('a')]\n",
    "    \n",
    "    jd = extract_jd_premium(job)\n",
    "    \n",
    "    general_info = extract_general_info_premium(job)\n",
    "    \n",
    "    related_tags = extract_related_tags_premium(job)\n",
    "    \n",
    "    return {\n",
    "        'url': url, \n",
    "        'title': job_title, \n",
    "        'location': location, \n",
    "        'salary': salary, \n",
    "        'exp': exp, \n",
    "        'job_tags': job_tags, \n",
    "        'jd': jd, \n",
    "        'general_info': general_info, \n",
    "        'related_tags': related_tags\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836e2650",
   "metadata": {},
   "source": [
    "### main ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ebbf69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_detail_urls = crawl_urls(max_page=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d2b1104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping  https://www.topcv.vn/viec-lam/data-engineer/1927366.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/junior-security-engineer-upto-35tr-thang/1926793.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/chuyen-vien-phan-tich-nghiep-vu-business-analyst/1926866.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/business-analyst/1927367.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/technical-leader-net-tu-2-nam-kinh-nghiem/1909066.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/chuyen-vien-tu-van-giai-phap-presale/1927330.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/nhan-vien-2d-artist-game/1926955.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/senior-frontend-developer/1927310.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/nhan-vien-junior-designer-ui-ux-khong-yeu-cau-kinh-nghiem/1926823.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/tester-tieng-nhat-n2-khong-yeu-cau-kinh-nghiem/1783338.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/java-developer/1925784.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/flutter-lead-mobile-lead-fintech-luong-upto-50m/1923715.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/quan-ly-khach-hang-am/1925444.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/nhan-vien-tu-van-giai-phap-cong-nghe-thong-tin/1926248.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/nhan-vien-lap-trinh-van-hanh-may-cnc/1750765.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/nhan-vien-nghien-cuu-va-phat-trien-cong-nghe-ai-phan-mem-nganh-duoc-y-te-khu-vuc-hcm-hn/1926007.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/executive-it-support/1926095.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/fresher-pentest/1906167.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/truong-phong-kinh-doanh-phan-mem-thu-nhap-trung-binh-20-40-trieu/1924498.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n",
      "scraping  https://www.topcv.vn/viec-lam/design-marketing-graphic-design-2d-nganh-bat-san-thu-nhap-20-trieu/1772452.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for url in job_detail_urls[:20]:\n",
    "    print('scraping  ' + url)\n",
    "\n",
    "    if url[21:29] == 'viec-lam':\n",
    "        res = scrape_normal_job(url)\n",
    "\n",
    "    elif url[21:26] == 'brand':\n",
    "        # detecting normal brand job or premium brand job\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        premium = soup.find('div', class_='premium-job')\n",
    "        \n",
    "        if premium is None:\n",
    "            res = scrape_brand_job(url)\n",
    "        else:\n",
    "            res = scrape_premium_brand_job(url)\n",
    "\n",
    "    else: \n",
    "        print('skipped ' + url)\n",
    "        continue\n",
    "    \n",
    "    if data is not None:\n",
    "        data.append(res)\n",
    "        print('Done')\n",
    "\n",
    "        time.sleep(random.uniform(1, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b97b0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/SelfLearning/crawlingdata/topcv/data/topcv_it_jobs_sample.json', 'w', encoding='utf-8') as f:\n",
    "    import json\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "874bf349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://www.topcv.vn/viec-lam/nhan-vien-2d-artist-game/1926955.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361',\n",
       " 'title': 'Nhân Viên 2D Artist Game',\n",
       " 'location': 'Hà Nội',\n",
       " 'salary': 'Thoả thuận',\n",
       " 'exp': '2 năm',\n",
       " 'deadline': '24/11/2025',\n",
       " 'jd_tags': ['Chuyên môn Game Design', 'IT - Phần mềm', 'Nghỉ thứ 7'],\n",
       " 'jd': {'Mô tả công việc': 'Tham gia thiết kế cho các dự án\\nTham gia nghiên cứu định hướng đồ hoạ Game\\nTham gia giải quyết vấn đề dự án, quy trình\\nHọc hỏi phát triển kỹ năng chuyên môn\\nPhát triển kỹ năng làm việc nhóm',\n",
       "  'Yêu cầu ứng viên': 'Đam mê với Game và đồ họa Game\\nKỹ năng Digital drawing tốt\\nCó tư duy hội họa, vẽ tốt, biết làm effect\\nCó kinh nghiệm về thiết kế nhân vật, môi trường, UI\\nAm hiểu về Photoshop hay các công cụ art digital khác\\nTính cam kết và tinh thần trách nhiệm cao\\nHam học hỏi, chủ động nâng cao kiến thức và kỹ năng trong công việc\\nHiểu về 3D modeling, Game design, Animation là một lợi thế\\nỨng viên có tối thiểu ≥2 năm kinh nghiệm',\n",
       "  'Quyền lợi': 'Mức lương: thỏa thuận\\nLương Review 1 lần/năm\\nThưởng Lương theo dự án, thưởng hiệu quả kinh doanh hàng năm\\nLàm việc tại môi trường thoải mái, trẻ trung, chuyên nghiệp khuyến khích sự sáng tạo và phát triển cá nhân.\\nCác chế độ chính sách đầy đủ theo luật lao động: BHXH, BHYT, BHTN, nghỉ lễ tết\\nLàm việc từ thứ 2 đến thứ 6. Giờ làm việc: từ 9h00 - 18h00.\\nĐược hỗ trợ thiết bị làm việc như máy tính, các thiết bị chơi/test app, game,...',\n",
       "  'Địa điểm làm việc': '- Hà Nội: số 112 Trần Phú, Mộ Lao, Hà Đông, Hà Đông',\n",
       "  'Thời gian làm việc': 'Thứ 2 - Thứ 6 (từ 09:00 đến 18:00)',\n",
       "  'Cách thức ứng tuyển': 'Ứng viên nộp hồ sơ trực tuyến bằng cách bấm\\nỨng tuyển\\nngay dưới đây.'},\n",
       " 'company_info': {'company_name': 'CÔNG TY TNHH ULT VIỆT NAM',\n",
       "  'company_scale': '500-1000 nhân viên',\n",
       "  'company_address': 'Tòa Ellipse số 110 Trần Phú, Hà Đông, Hà Nội',\n",
       "  'company_field': 'IT - Phần mềm'},\n",
       " 'general_inf': {'Cấp bậc': 'Nhân viên',\n",
       "  'Học vấn': 'Cao Đẳng trở lên',\n",
       "  'Số lượng tuyển': '1 người',\n",
       "  'Hình thức làm việc': 'Toàn thời gian'},\n",
       " 'categories': {'Danh mục Nghề liên quan': ['Công nghệ Thông tin',\n",
       "   'Thiết kế',\n",
       "   'Game Development',\n",
       "   'Nghệ thuật/Hoạt hình/Game',\n",
       "   'Game Design',\n",
       "   'Việc làm IT'],\n",
       "  'Khu vực': ['Hà Nội', 'Hà Đông - Hà Nội']}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_normal_job(\"https://www.topcv.vn/viec-lam/nhan-vien-2d-artist-game/1926955.html?ta_source=JobSearchList_LinkDetail&u_sr_id=aOxDEuuHPibDfkrFSMzdYmj5Yu0msCLHhNEqy3DM_1761447361\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6797ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910469d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c9b3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0e0703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21be497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929959e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b78200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e68116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69c6f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5fa533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f19d97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c028249b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e8aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e65f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfe20ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f5856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ef540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c01e1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b9a975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3acbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb4e054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234652f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
